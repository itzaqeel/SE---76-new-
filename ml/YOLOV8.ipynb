{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":100737,"status":"ok","timestamp":1710599141228,"user":{"displayName":"Ayyub Hameem","userId":"04962790387129176212"},"user_tz":-330},"id":"ZzXyRnSi84yp","outputId":"51741f0d-d6e9-4c9b-f284-0dacfb0e615d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.1.29-py3-none-any.whl (721 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.3/721.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.1+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.17.1+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Collecting thop>=0.1.1 (from ultralytics)\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.49.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.1.29\n"]}],"source":["!pip install ultralytics"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vKkImgecbAa_","outputId":"34ad170e-8cfb-46c0-bfb5-ba9f1d224e60","executionInfo":{"status":"ok","timestamp":1710599288933,"user_tz":-330,"elapsed":8343,"user":{"displayName":"Ayyub Hameem","userId":"04962790387129176212"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n"]}],"source":["## importing required libraries\n","import os\n","import shutil\n","import random\n","import torch\n","\n","!pip install tqdm --upgrade\n","from tqdm.notebook import tqdm"]},{"cell_type":"code","source":["train_path_img = \"./yolo_data/images/train/\"\n","train_path_label = \"./yolo_data/labels/train/\"\n","val_path_img = \"./yolo_data/images/val/\"\n","val_path_label = \"./yolo_data/labels/val/\"\n","test_path_img = \"./yolo_data/test\""],"metadata":{"id":"gGgTCKVyukcj"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GXuasXEebBPp","executionInfo":{"status":"ok","timestamp":1710599277664,"user_tz":-330,"elapsed":20810,"user":{"displayName":"Ayyub Hameem","userId":"04962790387129176212"}},"outputId":"5b05ffed-5390-47a9-e11a-d325bc3dc40a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["## connecting to the google drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200,"referenced_widgets":["1b3d2f68557f470c9153c522c1330a5a","e2208239901442afbefd4555f9197d3a","42297cceecfd4a7f93bf86a266881cf3","254f26c5acd74a448bec4bf2e88b7480","4d0b86c4a345402e8e31ad436c5c5848","c9dbfd7e5e7442c38b15d3cd29771983","c473f02c391f40ec9f1938f4ab7882d0","7f73a3fe95394fdbb33c294017b7d3f1","54ddadeb183d4cf58c4c5f06730e3b92","fb867800ccc14169951f917404811556","61212a1500b84e77b488c84e70f1c2f4","1496befb56dd4e5cbfa83d14c8fcee10","48b32659bb3048a58b347a40461a526f","7c159ef033814aba9050c5270d5bb87d","ff89dfc0cf56442d906334696a021e40","46173f6c83404b45b59cb030a73f3e86","490363470fe3465a9bce32e8062f6717","20f99fdbf13049d29cf19a5372556d4d","c4ce290d6b034d86b608c1b95bd6955a","ed5d747828d14741a0b617b30c7d9f0a","8de95aca130e49ef81b9e13daf80f6ad","5eb00e1f16874b7c9d8bc45817626c0c","89c70fe7139a4f68a732ef5900cb8def","f1a880563e9048ed897d49a4e608fce5","b586f0966559496e8d85d590a7b3d9ad","a428bb7261ce4c4894345a0491de00fd","454d4ea61f3b468db6becd5b56321ee8","394d57132d9b4996b9acb52aa0961c08","83b8d7063ff440b1bcf766ebd132f70d","9f4ef4e533354b7fab1fd19524a8a338","a654b1f7bde24bd99d0c1d31b1f64cb3","1652bc354f0d403abfc0fd44649f44f2","83e8245dd52c48dfbb6e4e5fffd4e3a0"]},"id":"y5_ZXOG0l1NR","executionInfo":{"status":"ok","timestamp":1710599582001,"user_tz":-330,"elapsed":293070,"user":{"displayName":"Ayyub Hameem","userId":"04962790387129176212"}},"outputId":"794471f3-67d0-4c77-84b0-5a53244f3b78"},"outputs":[{"output_type":"stream","name":"stdout","text":["------ PROCESS STARTED -------\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2692 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b3d2f68557f470c9153c522c1330a5a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["------ Training data created with 2692 images -------\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/184 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1496befb56dd4e5cbfa83d14c8fcee10"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["------ Validation data created with 184 images ----------\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/88 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89c70fe7139a4f68a732ef5900cb8def"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["------ Testing data created with 88 images ----------\n","------ TASK COMPLETED -------\n"]}],"source":["def train_test_split(train_path, test_path, val_path):\n","    print(\"------ PROCESS STARTED -------\")\n","\n","    os.makedirs(train_path_img, exist_ok=True)\n","    os.makedirs(train_path_label, exist_ok=True)\n","    os.makedirs(val_path_img, exist_ok=True)\n","    os.makedirs(val_path_label, exist_ok=True)\n","    os.makedirs(test_path_img, exist_ok=True)\n","\n","\n","    ### ----------- copying images to train folder\n","    train_files = list(set([name[:-4] for name in os.listdir(train_path)]))\n","    for filex in tqdm(train_files):\n","        if filex == 'classes':\n","            continue\n","        shutil.copy2(train_path + filex + '.jpg', f\"{train_path_img}/\" + filex + '.jpg')\n","        shutil.copy2(train_path + filex + '.txt', f\"{train_path_label}/\" + filex + '.txt')\n","\n","    print(f\"------ Training data created with {len(train_files)} images -------\")\n","\n","    ### copying images to validation folder\n","    val_files = list(set([name[:-4] for name in os.listdir(val_path)]))\n","    for filex in tqdm(val_files):\n","        if filex == 'classes':\n","            continue\n","        shutil.copy2(val_path + filex + '.jpg', f\"{val_path_img}/\" + filex + '.jpg')\n","        shutil.copy2(val_path + filex + '.txt', f\"{val_path_label}/\" + filex + '.txt')\n","\n","    print(f\"------ Validation data created with {len(val_files)} images ----------\")\n","\n","    ### copying images to test folder\n","    test_files = list(set([name[:-4] for name in os.listdir(test_path)]))\n","    for filex in tqdm(test_files):\n","        shutil.copy2(test_path + filex + '.jpg', f\"{test_path_img}/\" + filex + '.jpg')\n","\n","    print(f\"------ Testing data created with {len(test_files)} images ----------\")\n","\n","    print(\"------ TASK COMPLETED -------\")\n","\n","# Specify the paths to the test and val data folders\n","test_data_path = '/content/drive/MyDrive/yolov8/test/'\n","val_data_path = '/content/drive/MyDrive/yolov8/valid/'\n","\n","# Specify the path to the training data folder\n","train_data_path = '/content/drive/MyDrive/yolov8/train/'\n","\n","# Split the data and create train, test, and validation sets\n","train_test_split(train_data_path, test_data_path, val_data_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a0w2ToaV5oos","executionInfo":{"status":"ok","timestamp":1709616895992,"user_tz":-330,"elapsed":2810,"user":{"displayName":"Ayyub Hameem","userId":"04962790387129176212"}},"outputId":"df1910f8-4251-4de8-d6c1-0e2d344bad7f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.1.23 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete ✅ (2 CPUs, 12.7 GB RAM, 27.0/78.2 GB disk)\n"]}],"source":["import ultralytics\n","ultralytics.checks()"]},{"cell_type":"markdown","metadata":{"id":"oNo6iZS9owPm"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"emIRVrlll4ve","outputId":"952c1a56-e90d-4601-d632-050cc96c114b","executionInfo":{"status":"ok","timestamp":1710603669205,"user_tz":-330,"elapsed":1904936,"user":{"displayName":"Ayyub Hameem","userId":"04962790387129176212"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8s.pt to 'yolov8s.pt'...\n","100% 21.5M/21.5M [00:00<00:00, 159MB/s]\n","Ultralytics YOLOv8.1.29 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/drive/MyDrive/yolov8/dataset.yaml, epochs=50, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/drive/MyDrive/yolov8/training_results, name=plastic_bottle99, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.0001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/yolov8/training_results/plastic_bottle99\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","100% 755k/755k [00:00<00:00, 17.1MB/s]\n","2024-03-16 14:34:51.075077: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-16 14:34:51.075184: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-16 14:34:51.174411: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","Overriding model.yaml nc=80 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n","Model summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n","\n","Transferred 349/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/yolov8/training_results/plastic_bottle99', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n","100% 6.23M/6.23M [00:00<00:00, 84.3MB/s]\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_data/labels/train... 2692 images, 3 backgrounds, 0 corrupt: 100% 2692/2692 [00:01<00:00, 2231.58it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolo_data/labels/train.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_data/labels/val... 184 images, 1 backgrounds, 0 corrupt: 100% 184/184 [00:00<00:00, 1608.52it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo_data/labels/val.cache\n","Plotting labels to /content/drive/MyDrive/yolov8/training_results/plastic_bottle99/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.0001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/drive/MyDrive/yolov8/training_results/plastic_bottle99\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/50      8.03G      1.225      1.501      1.477         11        640: 100% 85/85 [01:17<00:00,  1.10it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:05<00:00,  1.78s/it]\n","                   all        184        277      0.678      0.635      0.627      0.398\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/50      8.11G      1.371      1.289      1.559         11        640: 100% 85/85 [01:15<00:00,  1.13it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.01s/it]\n","                   all        184        277      0.534       0.56      0.578       0.33\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/50       8.1G      1.386      1.272      1.576         18        640: 100% 85/85 [01:13<00:00,  1.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.08it/s]\n","                   all        184        277      0.615      0.592        0.6      0.372\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/50      8.14G      1.357      1.233      1.552         10        640: 100% 85/85 [01:14<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.08s/it]\n","                   all        184        277      0.675      0.628      0.707       0.48\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/50      8.25G      1.323      1.149       1.52         10        640: 100% 85/85 [01:13<00:00,  1.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.07it/s]\n","                   all        184        277      0.842      0.692       0.81      0.521\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/50      8.12G      1.236      1.056      1.455          6        640: 100% 85/85 [01:15<00:00,  1.13it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.15s/it]\n","                   all        184        277      0.876      0.863      0.936      0.672\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/50       8.1G      1.216      1.058      1.443         14        640: 100% 85/85 [01:13<00:00,  1.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.10it/s]\n","                   all        184        277      0.911      0.852      0.935      0.664\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/50      8.23G      1.177      1.017      1.422         15        640: 100% 85/85 [01:15<00:00,  1.13it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.08it/s]\n","                   all        184        277      0.876      0.798      0.878      0.636\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/50      8.08G      1.162     0.9855      1.404         17        640: 100% 85/85 [01:12<00:00,  1.18it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.09s/it]\n","                   all        184        277      0.923      0.869      0.917      0.679\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/50      8.17G      1.123     0.9494       1.38         11        640: 100% 85/85 [01:14<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.09it/s]\n","                   all        184        277      0.951      0.899      0.933      0.688\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      11/50       8.1G      1.079     0.9013      1.342         12        640: 100% 85/85 [01:14<00:00,  1.14it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.17it/s]\n","                   all        184        277      0.944      0.906      0.964      0.734\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      12/50      8.17G       1.07     0.8705      1.331         14        640: 100% 85/85 [01:12<00:00,  1.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:04<00:00,  1.40s/it]\n","                   all        184        277      0.918      0.932      0.955      0.709\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      13/50      8.13G      1.037     0.8662      1.312         12        640: 100% 85/85 [01:12<00:00,  1.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.10it/s]\n","                   all        184        277      0.954      0.903      0.951      0.728\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      14/50      8.17G      1.041      0.842      1.318          5        640: 100% 85/85 [01:12<00:00,  1.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.10s/it]\n","                   all        184        277      0.962      0.903      0.964       0.73\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      15/50      8.13G      1.028     0.8354      1.297         12        640: 100% 85/85 [01:14<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.09it/s]\n","                   all        184        277      0.945      0.932      0.973      0.734\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      16/50      8.11G      1.001     0.7947      1.283         12        640: 100% 85/85 [01:13<00:00,  1.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.11s/it]\n","                   all        184        277      0.954      0.904      0.949       0.69\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      17/50       8.1G      1.008      0.812       1.29         14        640: 100% 85/85 [01:14<00:00,  1.14it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.01s/it]\n","                   all        184        277      0.976       0.87      0.962      0.748\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      18/50      8.12G     0.9712     0.7755      1.265         12        640: 100% 85/85 [01:12<00:00,  1.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.08it/s]\n","                   all        184        277      0.958       0.91      0.949      0.741\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      19/50       8.1G     0.9498     0.7586      1.246          9        640: 100% 85/85 [01:14<00:00,  1.14it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.24s/it]\n","                   all        184        277      0.973      0.903      0.954       0.75\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      20/50      8.17G     0.9501      0.766      1.246         17        640: 100% 85/85 [01:12<00:00,  1.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.11it/s]\n","                   all        184        277      0.956      0.924      0.959       0.75\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      21/50      8.09G     0.9401     0.7373       1.24          8        640: 100% 85/85 [01:15<00:00,  1.13it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.17it/s]\n","                   all        184        277      0.972      0.895      0.961      0.771\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      22/50      8.13G     0.9159       0.74      1.237          6        640: 100% 85/85 [01:12<00:00,  1.18it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.19s/it]\n","                   all        184        277      0.963      0.903      0.939      0.755\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      23/50       8.1G     0.9155     0.7134      1.227         15        640: 100% 85/85 [01:12<00:00,  1.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.13it/s]\n","                   all        184        277      0.975      0.906       0.95      0.753\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      24/50      8.17G     0.9124     0.7462       1.23         11        640: 100% 85/85 [01:14<00:00,  1.14it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.21s/it]\n","                   all        184        277      0.958      0.902      0.945      0.749\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      25/50      8.13G     0.8995     0.7155      1.221         20        640: 100% 85/85 [01:12<00:00,  1.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.12it/s]\n","                   all        184        277      0.971      0.921      0.959      0.783\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      26/50      8.13G     0.8748     0.6968      1.206         13        640: 100% 85/85 [01:14<00:00,  1.14it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.08it/s]\n","                   all        184        277      0.942      0.946       0.97      0.785\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      27/50      8.09G     0.8575     0.6891       1.19         13        640: 100% 85/85 [01:13<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.06it/s]\n","                   all        184        277      0.973      0.903      0.951      0.757\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      28/50      8.21G     0.8516     0.6882      1.182         12        640: 100% 85/85 [01:13<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.20s/it]\n","                   all        184        277      0.977      0.917      0.962      0.769\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      29/50      8.18G     0.8304     0.6596      1.174          9        640: 100% 85/85 [01:12<00:00,  1.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.09it/s]\n","                   all        184        277      0.946      0.888      0.935      0.757\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      30/50      8.17G     0.8362     0.6601       1.17          9        640: 100% 85/85 [01:14<00:00,  1.13it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.13it/s]\n","                   all        184        277       0.95      0.921      0.942      0.753\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      31/50      8.09G     0.8049     0.6391      1.161         15        640: 100% 85/85 [01:12<00:00,  1.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.13s/it]\n","                   all        184        277      0.973      0.921      0.957      0.781\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      32/50      8.17G     0.8019     0.6293       1.15         19        640: 100% 85/85 [01:13<00:00,  1.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.11s/it]\n","                   all        184        277      0.956       0.93      0.967      0.788\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      33/50      8.13G     0.8002     0.6296      1.159         12        640: 100% 85/85 [01:12<00:00,  1.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.17it/s]\n","                   all        184        277      0.966      0.921      0.957      0.772\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      34/50      8.13G     0.7948     0.5998      1.151          8        640: 100% 85/85 [01:12<00:00,  1.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.13s/it]\n","                   all        184        277      0.948      0.916       0.95       0.77\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      35/50      8.09G      0.775      0.598      1.138         22        640: 100% 85/85 [01:13<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.16it/s]\n","                   all        184        277      0.962      0.903      0.959      0.791\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      36/50      8.13G     0.7649     0.5926      1.138         13        640: 100% 85/85 [01:13<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.07it/s]\n","                   all        184        277      0.966      0.931      0.965        0.8\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      37/50       8.2G       0.76     0.6053      1.134         15        640: 100% 85/85 [01:14<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.06it/s]\n","                   all        184        277      0.962      0.935      0.968      0.803\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      38/50      8.18G     0.7259     0.5628       1.11          8        640: 100% 85/85 [01:12<00:00,  1.18it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.33s/it]\n","                   all        184        277      0.941      0.935      0.959       0.79\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      39/50      8.13G     0.7265     0.5666      1.114          7        640: 100% 85/85 [01:13<00:00,  1.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.17it/s]\n","                   all        184        277      0.973      0.914       0.95      0.792\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      40/50      8.16G      0.721      0.562      1.113         10        640: 100% 85/85 [01:14<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.07it/s]\n","                   all        184        277      0.966      0.919      0.966      0.799\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      41/50       8.1G     0.6502     0.5011      1.083          9        640: 100% 85/85 [01:16<00:00,  1.12it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.15it/s]\n","                   all        184        277      0.952      0.928      0.968      0.801\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      42/50      8.12G     0.6067     0.4646       1.06          8        640: 100% 85/85 [01:09<00:00,  1.22it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.15it/s]\n","                   all        184        277       0.97      0.921       0.96        0.8\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      43/50      8.09G     0.5982     0.4426      1.045          5        640: 100% 85/85 [01:09<00:00,  1.22it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.18s/it]\n","                   all        184        277      0.966      0.918      0.952      0.797\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      44/50      8.13G      0.584     0.4354      1.036          4        640: 100% 85/85 [01:11<00:00,  1.19it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.19it/s]\n","                   all        184        277      0.972      0.921      0.958      0.808\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      45/50      8.08G     0.5557      0.419      1.023          4        640: 100% 85/85 [01:09<00:00,  1.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.00s/it]\n","                   all        184        277      0.964      0.939      0.963      0.804\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      46/50      8.13G     0.5552     0.4078       1.02          4        640: 100% 85/85 [01:11<00:00,  1.20it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.17it/s]\n","                   all        184        277      0.966      0.928      0.956      0.808\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      47/50       8.1G     0.5401     0.4011      1.006          6        640: 100% 85/85 [01:08<00:00,  1.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.16it/s]\n","                   all        184        277      0.966       0.92      0.951      0.808\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      48/50      8.16G     0.5121     0.3799     0.9883          4        640: 100% 85/85 [01:09<00:00,  1.22it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.26s/it]\n","                   all        184        277      0.965      0.931       0.96      0.816\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      49/50      8.09G     0.5114     0.3805     0.9919          4        640: 100% 85/85 [01:09<00:00,  1.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.15it/s]\n","                   all        184        277      0.979      0.924      0.958      0.809\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      50/50      8.13G     0.4939     0.3705     0.9811          4        640: 100% 85/85 [01:09<00:00,  1.22it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.10it/s]\n","                   all        184        277       0.97      0.927      0.965      0.821\n","\n","50 epochs completed in 1.094 hours.\n","Optimizer stripped from /content/drive/MyDrive/yolov8/training_results/plastic_bottle99/weights/last.pt, 22.5MB\n","Optimizer stripped from /content/drive/MyDrive/yolov8/training_results/plastic_bottle99/weights/best.pt, 22.5MB\n","\n","Validating /content/drive/MyDrive/yolov8/training_results/plastic_bottle99/weights/best.pt...\n","Ultralytics YOLOv8.1.29 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:04<00:00,  1.53s/it]\n","                   all        184        277       0.97      0.927      0.965      0.821\n","Speed: 0.2ms preprocess, 4.8ms inference, 0.0ms loss, 3.5ms postprocess per image\n","Results saved to \u001b[1m/content/drive/MyDrive/yolov8/training_results/plastic_bottle99\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}],"source":["!yolo task=detect mode=train model=yolov8s.pt data=/content/drive/MyDrive/yolov8/dataset.yaml epochs=50 imgsz=640 batch=32 lr0=0.0001 project=/content/drive/MyDrive/yolov8/training_results name=plastic_bottle99"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23900,"status":"ok","timestamp":1710604773658,"user":{"displayName":"Ayyub Hameem","userId":"04962790387129176212"},"user_tz":-330},"id":"M7yb9r65hMzX","outputId":"d4fcb294-53cb-400b-cddf-0a8371ea8b4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'\n","  warnings.warn(\n","Ultralytics YOLOv8.1.29 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 11126358 parameters, 0 gradients, 28.4 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_data/labels/val.cache... 184 images, 1 backgrounds, 0 corrupt: 100% 184/184 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:07<00:00,  1.61it/s]\n","                   all        184        277      0.958      0.931      0.962      0.801\n","        plastic bottle        184        277      0.958      0.931      0.962      0.801\n","Speed: 3.3ms preprocess, 10.4ms inference, 0.0ms loss, 6.6ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/val\n"]}],"source":["!yolo task=detect mode=val model=/content/drive/MyDrive/yolov8/training_results/plastic_bottle23/weights/best.pt data=/content/drive/MyDrive/yolov8/dataset.yaml"]},{"cell_type":"markdown","metadata":{"id":"j36y7pZsqqJT"},"source":["# Inferencing/Prediction"]},{"cell_type":"code","source":["!pip install tensorflow==2.13.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"dLCAJJWmMDAX","executionInfo":{"status":"ok","timestamp":1710604625768,"user_tz":-330,"elapsed":75793,"user":{"displayName":"Ayyub Hameem","userId":"04962790387129176212"}},"outputId":"fbc2dd61-0049-412a-cf4b-c7d21a594d0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow==2.13.1\n","  Downloading tensorflow-2.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.7/479.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (24.3.7)\n","Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.13.1)\n","  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (1.62.1)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (3.9.0)\n","Collecting keras<2.14,>=2.13.1 (from tensorflow==2.13.1)\n","  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (16.0.6)\n","Collecting numpy<=1.24.3,>=1.22 (from tensorflow==2.13.1)\n","  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (1.16.0)\n","Collecting tensorboard<2.14,>=2.13 (from tensorflow==2.13.1)\n","  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow==2.13.1)\n","  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (2.4.0)\n","Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow==2.13.1)\n","  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.1) (0.36.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.1) (0.43.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.1) (2.27.0)\n","Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow==2.13.1)\n","  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.1) (3.5.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.1) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.1) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.1) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (1.4.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (2.1.5)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (3.2.2)\n","Installing collected packages: typing-extensions, tensorflow-estimator, numpy, keras, gast, google-auth-oauthlib, tensorboard, tensorflow\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.10.0\n","    Uninstalling typing_extensions-4.10.0:\n","      Successfully uninstalled typing_extensions-4.10.0\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.15.0\n","    Uninstalling tensorflow-estimator-2.15.0:\n","      Successfully uninstalled tensorflow-estimator-2.15.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.25.2\n","    Uninstalling numpy-1.25.2:\n","      Successfully uninstalled numpy-1.25.2\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.15.0\n","    Uninstalling keras-2.15.0:\n","      Successfully uninstalled keras-2.15.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.5.4\n","    Uninstalling gast-0.5.4:\n","      Successfully uninstalled gast-0.5.4\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.2.0\n","    Uninstalling google-auth-oauthlib-1.2.0:\n","      Successfully uninstalled google-auth-oauthlib-1.2.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.15.2\n","    Uninstalling tensorboard-2.15.2:\n","      Successfully uninstalled tensorboard-2.15.2\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.15.0\n","    Uninstalling tensorflow-2.15.0:\n","      Successfully uninstalled tensorflow-2.15.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sqlalchemy 2.0.28 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n","pydantic 2.6.4 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\n","pydantic-core 2.16.3 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n","tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.13.1 which is incompatible.\n","torch 2.2.1+cu121 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 keras-2.13.1 numpy-1.24.3 tensorboard-2.13.0 tensorflow-2.13.1 tensorflow-estimator-2.13.0 typing-extensions-4.5.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"817271696e434773be82566b43d62821"}},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"948bxTfnHQfn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710604734664,"user_tz":-330,"elapsed":43449,"user":{"displayName":"Ayyub Hameem","userId":"04962790387129176212"}},"outputId":"b923ac97-1a18-4405-b233-c7bf648a9d33"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'\n","  warnings.warn(\n","Ultralytics YOLOv8.1.29 🚀 Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.30GHz)\n","Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/drive/MyDrive/yolov8/training_results/plastic_bottle99/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (21.5 MB)\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0', 'onnx2tf>=1.15.4,<=1.17.5', 'sng4onnx>=1.0.1', 'onnxsim>=0.4.33', 'onnx_graphsurgeon>=0.3.26', 'tflite_support', 'onnxruntime'] not found, attempting AutoUpdate...\n","Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n","Collecting onnx>=1.12.0\n","  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.7/15.7 MB 80.5 MB/s eta 0:00:00\n","Collecting onnx2tf<=1.17.5,>=1.15.4\n","  Downloading onnx2tf-1.17.5-py3-none-any.whl (400 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 400.4/400.4 kB 341.5 MB/s eta 0:00:00\n","Collecting sng4onnx>=1.0.1\n","  Downloading sng4onnx-1.0.1-py3-none-any.whl (5.8 kB)\n","Collecting onnxsim>=0.4.33\n","  Downloading onnxsim-0.4.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 249.8 MB/s eta 0:00:00\n","Collecting onnx_graphsurgeon>=0.3.26\n","  Downloading https://developer.download.nvidia.com/compute/redist/onnx-graphsurgeon/onnx_graphsurgeon-0.3.27-py2.py3-none-any.whl (42 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.1/42.1 kB 223.2 MB/s eta 0:00:00\n","Collecting tflite_support\n","  Downloading tflite_support-0.4.4-cp310-cp310-manylinux2014_x86_64.whl (60.8 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.8/60.8 MB 65.5 MB/s eta 0:00:00\n","Collecting onnxruntime\n","  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.8/6.8 MB 77.6 MB/s eta 0:00:00\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (1.24.3)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (3.20.3)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from onnxsim>=0.4.33) (13.7.1)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tflite_support) (1.4.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tflite_support) (24.3.7)\n","Collecting sounddevice>=0.4.4 (from tflite_support)\n","  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n","Collecting pybind11>=2.6.0 (from tflite_support)\n","  Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 227.7/227.7 kB 75.3 MB/s eta 0:00:00\n","Collecting coloredlogs (from onnxruntime)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 136.0 MB/s eta 0:00:00\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->tflite_support) (1.16.0)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 270.2 MB/s eta 0:00:00\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnxsim>=0.4.33) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnxsim>=0.4.33) (2.16.1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->tflite_support) (2.21)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->onnxsim>=0.4.33) (0.1.2)\n","Installing collected packages: sng4onnx, pybind11, onnx2tf, onnx, humanfriendly, sounddevice, onnx_graphsurgeon, coloredlogs, tflite_support, onnxsim, onnxruntime\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.15.0 onnx2tf-1.17.5 onnx_graphsurgeon-0.3.27 onnxruntime-1.17.1 onnxsim-0.4.36 pybind11-2.11.1 sng4onnx-1.0.1 sounddevice-0.4.6 tflite_support-0.4.4\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 15.9s, installed 7 packages: ['onnx>=1.12.0', 'onnx2tf>=1.15.4,<=1.17.5', 'sng4onnx>=1.0.1', 'onnxsim>=0.4.33', 'onnx_graphsurgeon>=0.3.26', 'tflite_support', 'onnxruntime']\n","\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.13.1...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip'...\n","100% 1.11M/1.11M [00:00<00:00, 22.9MB/s]\n","Unzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip to /content/calibration_image_sample_data_20x128x128x3_float32.npy...: 100% 1/1 [00:00<00:00, 35.53file/s]\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0 opset 17...\n","\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.36...\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 3.7s, saved as '/content/drive/MyDrive/yolov8/training_results/plastic_bottle99/weights/best.onnx' (42.7 MB)\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.17.5...\n","2024-03-16 15:58:41.419776: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ✅ 32.9s, saved as '/content/drive/MyDrive/yolov8/training_results/plastic_bottle99/weights/best_saved_model' (106.9 MB)\n","\n","\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.13.1...\n","\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ✅ 0.0s, saved as '/content/drive/MyDrive/yolov8/training_results/plastic_bottle99/weights/best_saved_model/best_float32.tflite' (42.7 MB)\n","\n","Export complete (36.3s)\n","Results saved to \u001b[1m/content/drive/MyDrive/yolov8/training_results/plastic_bottle99/weights\u001b[0m\n","Predict:         yolo predict task=detect model=/content/drive/MyDrive/yolov8/training_results/plastic_bottle99/weights/best_saved_model/best_float32.tflite imgsz=640  \n","Validate:        yolo val task=detect model=/content/drive/MyDrive/yolov8/training_results/plastic_bottle99/weights/best_saved_model/best_float32.tflite imgsz=640 data=/content/drive/MyDrive/yolov8/dataset.yaml  \n","Visualize:       https://netron.app\n","💡 Learn more at https://docs.ultralytics.com/modes/export\n"]}],"source":["!yolo mode=export model=/content/drive/MyDrive/yolov8/training_results/plastic_bottle99/weights/best.pt format=tflite"]},{"cell_type":"code","source":[],"metadata":{"id":"oKhLF6cxLEx5"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12544,"status":"ok","timestamp":1710604865355,"user":{"displayName":"Ayyub Hameem","userId":"04962790387129176212"},"user_tz":-330},"id":"GAAoSVvJqouV","outputId":"087290e3-0fd8-4b6f-bce4-0bc6564d2ada"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'\n","  warnings.warn(\n","Ultralytics YOLOv8.1.29 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n","\n","image 1/88 /content/drive/MyDrive/yolov8/test/00010_01_jpg.rf.621e4060cddf1ca01788d4c8a118d5e8.jpg: 640x640 1 ObjectDetected, 25.3ms\n","image 2/88 /content/drive/MyDrive/yolov8/test/00011_02_jpg.rf.271d57de1e716d2f56600ed8387c032f.jpg: 640x640 1 ObjectDetected, 16.3ms\n","image 3/88 /content/drive/MyDrive/yolov8/test/00016_01_jpg.rf.0b3e17df62d4e035057e72cf8de89b42.jpg: 640x640 1 ObjectDetected, 16.3ms\n","image 4/88 /content/drive/MyDrive/yolov8/test/00024_04_jpg.rf.4cb904b52a4810f94f1b5835f15ef615.jpg: 640x640 1 ObjectDetected, 16.3ms\n","image 5/88 /content/drive/MyDrive/yolov8/test/00034_01_jpg.rf.3c8689f00cb084cb4df749ff3b2aeef9.jpg: 640x640 1 ObjectDetected, 16.3ms\n","image 6/88 /content/drive/MyDrive/yolov8/test/00041_04_jpg.rf.d8237b3de69091af72e0cdcdf92ced9c.jpg: 640x640 1 ObjectDetected, 16.4ms\n","image 7/88 /content/drive/MyDrive/yolov8/test/00044_05_jpg.rf.5f0c62d0ef5428a0bd78cbb8ab68209b.jpg: 640x640 2 ObjectDetecteds, 15.6ms\n","image 8/88 /content/drive/MyDrive/yolov8/test/00047_01_jpg.rf.4b8a79d8835b2aa79ced5e4a6e289142.jpg: 640x640 1 ObjectDetected, 15.6ms\n","image 9/88 /content/drive/MyDrive/yolov8/test/00048_07_jpg.rf.e0b187e68f48d0bbb0df21b1def02618.jpg: 640x640 1 ObjectDetected, 15.6ms\n","image 10/88 /content/drive/MyDrive/yolov8/test/00049_07_jpg.rf.f94b0d50d212ee0a2bf82ef944020cd3.jpg: 640x640 1 ObjectDetected, 15.6ms\n","image 11/88 /content/drive/MyDrive/yolov8/test/00050_06_jpg.rf.8182e7b9705b1909cbb2a0eefad885c4.jpg: 640x640 1 ObjectDetected, 15.6ms\n","image 12/88 /content/drive/MyDrive/yolov8/test/00052_04_jpg.rf.4c08c631708fa45ff79db66e1b9e3b26.jpg: 640x640 1 ObjectDetected, 15.7ms\n","image 13/88 /content/drive/MyDrive/yolov8/test/085105D4-613F-43FE-A86B-1F2D539E6C5F_jpeg_jpg.rf.0d5fdc3958c7d62f321585085a0d0b2c.jpg: 640x640 1 ObjectDetected, 15.6ms\n","image 14/88 /content/drive/MyDrive/yolov8/test/10-Tempat-Sampah-Bagus-Terbaik-di-_jpg.rf.0aa840d45a87fa85686ac3bdea488f4b.jpg: 640x640 1 ObjectDetected, 15.6ms\n","image 15/88 /content/drive/MyDrive/yolov8/test/120-Liter-garbage-bin-with-side-pedal-_jpg.rf.e50040ccf25fa074a9203f9119e7c32a.jpg: 640x640 1 ObjectDetected, 15.6ms\n","image 16/88 /content/drive/MyDrive/yolov8/test/15C3201D-0DF4-477C-BA82-C05F8E43DDDD_jpeg_jpg.rf.7500811f835846cf2b99711304c3543e.jpg: 640x640 1 ObjectDetected, 15.6ms\n","image 17/88 /content/drive/MyDrive/yolov8/test/1689532A-7B47-4B96-9AF2-74E8B98D4D30_jpeg_jpg.rf.c46b0468355fa11ea663f8e1ad9a88de.jpg: 640x640 2 ObjectDetecteds, 15.7ms\n","image 18/88 /content/drive/MyDrive/yolov8/test/17E951FC-6B90-4B0F-902E-6BD3C4E35838_jpeg_jpg.rf.6afd5e1ebfb51fae995ff6dae6068236.jpg: 640x640 1 ObjectDetected, 13.5ms\n","image 19/88 /content/drive/MyDrive/yolov8/test/1E901CB9-9629-4A98-9548-4DB50D8B0AD7_jpeg_jpg.rf.10ea1a40dbbafcc72a284195637d69d2.jpg: 640x640 1 ObjectDetected, 13.4ms\n","image 20/88 /content/drive/MyDrive/yolov8/test/20D8302A-E6A2-46A7-90BC-F167B61B2D19_jpeg_jpg.rf.51a0c726a002684cb685027e467a5c91.jpg: 640x640 1 ObjectDetected, 13.4ms\n","image 21/88 /content/drive/MyDrive/yolov8/test/20_886-Garbage-Bin-Photos-and-Premium-_jpg.rf.5240af9032d1a88dc142011018dd30f7.jpg: 640x640 1 ObjectDetected, 13.4ms\n","image 22/88 /content/drive/MyDrive/yolov8/test/21447A41-42C3-44F1-9802-D36D09C97975_jpeg_jpg.rf.5ade4a23f1938f538b3b8fc5b99e202a.jpg: 640x640 1 ObjectDetected, 13.4ms\n","image 23/88 /content/drive/MyDrive/yolov8/test/271AEF4E-5F06-4D4B-9212-1F2B7634B35A_jpeg_jpg.rf.2b773406519505574a3f35d765170c76.jpg: 640x640 1 ObjectDetected, 13.4ms\n","image 24/88 /content/drive/MyDrive/yolov8/test/395983551_349987230837856_7500587793414954104_n_jpg.rf.910bd072f642de656220fb0b07a6d6de.jpg: 640x480 1 ObjectDetected, 75.9ms\n","image 25/88 /content/drive/MyDrive/yolov8/test/Apa-Jadinya-jika-Tong-Sampah-Tidak-Ada-_jpg.rf.b48f80018e38c8aafa9a97f2b6f8a6d9.jpg: 640x640 (no detections), 14.2ms\n","image 26/88 /content/drive/MyDrive/yolov8/test/Atasi-Bau-Tak-Sedap-pada-Tong-Sampah-_jpg.rf.9908ca346bf9535c155e6606eff5a9bd.jpg: 640x640 1 ObjectDetected, 13.4ms\n","image 27/88 /content/drive/MyDrive/yolov8/test/Baby-bears-escape-garbage-bin-south-of-Reno_jpg.rf.ce3e3232b81861e9d707ba150c8dbcd0.jpg: 640x640 1 ObjectDetected, 13.6ms\n","image 28/88 /content/drive/MyDrive/yolov8/test/Balada-Tempat-Sampah-3-Warna-di-DKI_jpg.rf.dcab08d9f99b4c02c98a4430da707ea0.jpg: 640x640 2 ObjectDetecteds, 13.5ms\n","image 29/88 /content/drive/MyDrive/yolov8/test/Bin-Service-Commercial-Properties_jpg.rf.557d3d0c0bec1857d6a66c88fe77801d.jpg: 640x640 5 ObjectDetecteds, 13.5ms\n","image 30/88 /content/drive/MyDrive/yolov8/test/BoonHardware-LHHL0498GR-240-Litres-_jpg.rf.50e8fed0e5566507f4f6e0fb985cbaa2.jpg: 640x640 1 ObjectDetected, 13.5ms\n","image 31/88 /content/drive/MyDrive/yolov8/test/China-Garbage-Bin-and-Plastic-Waste-Bin-_jpg.rf.002f5eddda2cd45c225de97961a3db87.jpg: 640x640 2 ObjectDetecteds, 13.3ms\n","image 32/88 /content/drive/MyDrive/yolov8/test/DLHK-Karawang-Siapkan-Tong-Sampah-_jpg.rf.bf441fa9940eb4014e09f6fb25d180fd.jpg: 640x640 2 ObjectDetecteds, 13.3ms\n","image 33/88 /content/drive/MyDrive/yolov8/test/E48C5404-E0C5-4710-9227-AA5B86B98659_jpeg_jpg.rf.41bcffa7e8fb84b5b57226734de1a778.jpg: 640x640 1 ObjectDetected, 13.3ms\n","image 34/88 /content/drive/MyDrive/yolov8/test/E4DF1FFA-8678-4745-9D1B-775767E9EF20_jpeg_jpg.rf.3df16f2b6dc3c18fea4b4eb29aeb439d.jpg: 640x640 2 ObjectDetecteds, 13.3ms\n","image 35/88 /content/drive/MyDrive/yolov8/test/E6197943-041C-4943-A974-4666092BA986_jpeg_jpg.rf.ad5005a6e348547e73baf1701ba81b8a.jpg: 640x640 1 ObjectDetected, 13.2ms\n","image 36/88 /content/drive/MyDrive/yolov8/test/E73F019C-FA64-4169-AF9C-4AD715535124_jpeg_jpg.rf.edd18173bff055d44bad24722440e458.jpg: 640x640 1 ObjectDetected, 13.3ms\n","image 37/88 /content/drive/MyDrive/yolov8/test/EBB8E388-F698-44AF-84C4-C2103AF16662_jpeg_jpg.rf.68f687d72a67c9be010c77ee12f9e368.jpg: 640x640 2 ObjectDetecteds, 13.3ms\n","image 38/88 /content/drive/MyDrive/yolov8/test/ED224319-6019-4CCA-85A2-6F22C4F8CC12_jpeg_jpg.rf.1c97db163dcc40ff8a0c34d8da66ede6.jpg: 640x640 1 ObjectDetected, 13.3ms\n","image 39/88 /content/drive/MyDrive/yolov8/test/EE2D3FD9-5365-4CB5-879E-8D346A6CA05C_jpeg_jpg.rf.4f37f814dd37289afdcd532f367857c9.jpg: 640x640 1 ObjectDetected, 13.2ms\n","image 40/88 /content/drive/MyDrive/yolov8/test/F28F88D8-B878-49F2-B10F-86A212ECA79D_jpeg_jpg.rf.01b5c56021dcd9b294f79696b28896cd.jpg: 640x640 2 ObjectDetecteds, 13.2ms\n","image 41/88 /content/drive/MyDrive/yolov8/test/F29B18A2-E731-4AAE-9649-D99C8C7F0055_jpeg_jpg.rf.bdf07a4940ab0a8f0703d96a2b3137d7.jpg: 640x640 2 ObjectDetecteds, 13.3ms\n","image 42/88 /content/drive/MyDrive/yolov8/test/F340E92A-9B5C-4642-B00C-4B809A5AE974_jpeg_jpg.rf.dbf0618069fbf12cc66859c08824f078.jpg: 640x640 1 ObjectDetected, 13.3ms\n","image 43/88 /content/drive/MyDrive/yolov8/test/F9880BCE-1B0B-4CEA-A1D6-71E8572EB113_jpeg_jpg.rf.7e5ad9866ad6e85b1f03e937f6fd189c.jpg: 640x640 1 ObjectDetected, 13.3ms\n","image 44/88 /content/drive/MyDrive/yolov8/test/FE127435-135F-407D-99C2-245B457D9A38_jpeg_jpg.rf.086fe8f5d9a6d9341ade1a976faad870.jpg: 640x640 1 ObjectDetected, 13.3ms\n","image 45/88 /content/drive/MyDrive/yolov8/test/FF5C3F85-B407-41E9-9982-501D45977870_jpeg_jpg.rf.51581b56069ac4dd5fa9e531acce20ee.jpg: 640x640 2 ObjectDetecteds, 13.3ms\n","image 46/88 /content/drive/MyDrive/yolov8/test/Garbage-Bin-_-Trash-Bin-240L-Wintess-_jpg.rf.4f4d769616dfd7fbdffe66fc516e891b.jpg: 640x640 6 ObjectDetecteds, 14.3ms\n","image 47/88 /content/drive/MyDrive/yolov8/test/Harga-Tempat-Sampah-Content_jpg.rf.d06bd85063472a666cd7416d9a9b36d9.jpg: 640x640 1 ObjectDetected, 13.3ms\n","image 48/88 /content/drive/MyDrive/yolov8/test/IMG_20230914_101737_287_jpg.rf.49222c6393272ba5faa9cabed2c36834.jpg: 640x480 1 ObjectDetected, 11.8ms\n","image 49/88 /content/drive/MyDrive/yolov8/test/IMG_20230914_101828_100_jpg.rf.75928e64400631853f46b6dbafab61c5.jpg: 640x480 1 ObjectDetected, 10.0ms\n","image 50/88 /content/drive/MyDrive/yolov8/test/IMG_20230914_103708_037_jpg.rf.900cda72efd16c787aaffea17e45a240.jpg: 640x480 1 ObjectDetected, 9.9ms\n","image 51/88 /content/drive/MyDrive/yolov8/test/IMG_20231020_160639_713_jpg.rf.faaf901e71e3793c79e325bb42340ae7.jpg: 640x480 1 ObjectDetected, 9.9ms\n","image 52/88 /content/drive/MyDrive/yolov8/test/IMG_20231020_160700_296_jpg.rf.a527294612536674db6c00969e426736.jpg: 640x480 1 ObjectDetected, 9.9ms\n","image 53/88 /content/drive/MyDrive/yolov8/test/IMG_20231020_161113_641_jpg.rf.0d943608c97c3b28b75e231dcd419f9b.jpg: 640x480 1 ObjectDetected, 9.9ms\n","image 54/88 /content/drive/MyDrive/yolov8/test/IMG_20231020_161145_319_jpg.rf.b6289ce96a360e9d150ecf7a9b609ea2.jpg: 640x480 1 ObjectDetected, 9.9ms\n","image 55/88 /content/drive/MyDrive/yolov8/test/IMG_20231020_161504_461_jpg.rf.c4d67fb6b419c00d97dbbcefc2b5ae58.jpg: 640x480 1 ObjectDetected, 9.9ms\n","image 56/88 /content/drive/MyDrive/yolov8/test/IMG_20231020_161617_097_jpg.rf.86672ba9d14f23a9d07466eff0d3b1ca.jpg: 640x480 1 ObjectDetected, 10.0ms\n","image 57/88 /content/drive/MyDrive/yolov8/test/IMG_20231028_094939_921_jpg.rf.4a1b528d6916193a6b7527cacf845382.jpg: 640x480 1 ObjectDetected, 9.9ms\n","image 58/88 /content/drive/MyDrive/yolov8/test/IMG_20231028_095350_204_jpg.rf.5edc99746aa43375c252cb2b341a637c.jpg: 640x480 1 ObjectDetected, 12.1ms\n","image 59/88 /content/drive/MyDrive/yolov8/test/IMG_20231028_095359_262_jpg.rf.d8e8ed1c252f62e51c7c4ce1bed013b6.jpg: 640x480 1 ObjectDetected, 12.7ms\n","image 60/88 /content/drive/MyDrive/yolov8/test/IMG_20231028_095552_518_jpg.rf.69788cfb9763acdcf681d8e967d70060.jpg: 640x480 1 ObjectDetected, 12.1ms\n","image 61/88 /content/drive/MyDrive/yolov8/test/IMG_20231028_095813_693_jpg.rf.7e895b81503fc344704dbb8fd3d31ac1.jpg: 640x480 1 ObjectDetected, 12.1ms\n","image 62/88 /content/drive/MyDrive/yolov8/test/IMG_20231028_095954_665_jpg.rf.54bcf764612439dcb7515d8cab9384f0.jpg: 640x480 1 ObjectDetected, 12.2ms\n","image 63/88 /content/drive/MyDrive/yolov8/test/IMG_20231112_204115_718_jpg.rf.4e5624a5508d033cabb34afbd270e20d.jpg: 640x480 1 ObjectDetected, 12.1ms\n","image 64/88 /content/drive/MyDrive/yolov8/test/IMG_20231112_204536_376_jpg.rf.bcb68f3f1c6d61c854e684cf61ac1760.jpg: 640x480 1 ObjectDetected, 12.1ms\n","image 65/88 /content/drive/MyDrive/yolov8/test/JUAL-TONG-SAMPAH-FIBERGLASS-4-IN-1-1-_jpg.rf.4fcc1e071cb7de7151b36dcf439601d5.jpg: 640x640 4 ObjectDetecteds, 17.1ms\n","image 66/88 /content/drive/MyDrive/yolov8/test/JUAL-TONG-SAMPAH-FIBERGLASS-4-IN-1-_jpg.rf.612f06ecff78dd1ab5a8ce6a67eb5652.jpg: 640x640 4 ObjectDetecteds, 16.3ms\n","image 67/88 /content/drive/MyDrive/yolov8/test/Jual-Krisbow-45-Ltr-Tempat-Sampah-_jpg.rf.e9a47c52b7f587fd0ae88b0836e679eb.jpg: 640x640 1 ObjectDetected, 16.3ms\n","image 68/88 /content/drive/MyDrive/yolov8/test/Jual-Tempat-sampah-100-Liter-tong-_jpg.rf.9d7fec41c466ff5257acb6e74c451bff.jpg: 640x640 1 ObjectDetected, 16.3ms\n","image 69/88 /content/drive/MyDrive/yolov8/test/Jual-Tempat-sampah-Terpisah-60-Liter-di-_jpg.rf.446a7795092e4680970dfe974b59b17e.jpg: 640x640 5 ObjectDetecteds, 16.3ms\n","image 70/88 /content/drive/MyDrive/yolov8/test/Mendapatkan-Tong-Sampah-_jpg.rf.65d6b6304f3367c9a997dae555f49541.jpg: 640x640 2 ObjectDetecteds, 16.3ms\n","image 71/88 /content/drive/MyDrive/yolov8/test/Pabrik-Tong-Sampah-Fiber-Termurah-di-_jpg.rf.36a525ca572710e8d82884e291247d26.jpg: 640x640 5 ObjectDetecteds, 16.4ms\n","image 72/88 /content/drive/MyDrive/yolov8/test/Pemasangan-Tempat-Sampah-Terpilah-di-Jl-1-_jpg.rf.3ca18dd3c764600c841a2769156e7e5c.jpg: 640x640 4 ObjectDetecteds, 15.6ms\n","image 73/88 /content/drive/MyDrive/yolov8/test/Penyerahan-bantuan-tempat-sampah-di-_jpg.rf.ae931cb912771a451cccef15b319c7df.jpg: 640x640 7 ObjectDetecteds, 15.6ms\n","image 74/88 /content/drive/MyDrive/yolov8/test/SULO-MGB-Bin-Supplier-in-Malaysia-_-No-1-_jpg.rf.4462503a794254e336031f7d47b99c84.jpg: 640x640 1 ObjectDetected, 15.6ms\n","image 75/88 /content/drive/MyDrive/yolov8/test/SULO-MGB-Bin-Supplier-in-Malaysia-_-No-_jpg.rf.4afa9b061d6aeb10642674f62d1fc686.jpg: 640x640 1 ObjectDetected, 15.6ms\n","image 76/88 /content/drive/MyDrive/yolov8/test/Tempat-Sampah-Fiber-Bulat-2-IN-1-80-_jpg.rf.6e37efe2ca06a4ec43f4f71882dc8633.jpg: 640x640 2 ObjectDetecteds, 15.8ms\n","image 77/88 /content/drive/MyDrive/yolov8/test/Tempat-sampah-set-isi-1-bahan-tong-_jpg.rf.91eaf44298295ff190d4b9afc589defd.jpg: 640x640 1 ObjectDetected, 15.3ms\n","image 78/88 /content/drive/MyDrive/yolov8/test/WhatsApp-Image-2024-03-16-at-12-53-40_jpeg.rf.dc76a04880e763b8ae70edfdd6bdfb1a.jpg: 640x640 1 ObjectDetected, 15.3ms\n","image 79/88 /content/drive/MyDrive/yolov8/test/harga-tempat-sampah-bulat-_-Pabrik-_jpg.rf.ebdbfd0b440e78ec9b7ee18a6b0a3b26.jpg: 640x640 2 ObjectDetecteds, 15.3ms\n","image 80/88 /content/drive/MyDrive/yolov8/test/th-14-_jpeg_jpg.rf.9e08b2e661438a0f70090266138c5955.jpg: 640x640 1 ObjectDetected, 15.3ms\n","image 81/88 /content/drive/MyDrive/yolov8/test/th-36-_jpeg_jpg.rf.b28817ea8355d20d26ad11b591e5a6c6.jpg: 640x640 1 ObjectDetected, 15.3ms\n","image 82/88 /content/drive/MyDrive/yolov8/test/th-44-_jpeg_jpg.rf.89247142447b67d1c6dfb30b1e4394a5.jpg: 640x640 2 ObjectDetecteds, 15.3ms\n","image 83/88 /content/drive/MyDrive/yolov8/test/th-47-_jpeg_jpg.rf.1bcd83eb9dc2efa7b75e1bb1bcd51d8b.jpg: 640x640 3 ObjectDetecteds, 13.5ms\n","image 84/88 /content/drive/MyDrive/yolov8/test/th-48-_jpeg_jpg.rf.7438a6f41293b32e20a177ea07f4e2a3.jpg: 640x640 1 ObjectDetected, 13.5ms\n","image 85/88 /content/drive/MyDrive/yolov8/test/th-51-_jpeg_jpg.rf.059d44980a709666aa0b06e93f2fda66.jpg: 640x640 5 ObjectDetecteds, 13.5ms\n","image 86/88 /content/drive/MyDrive/yolov8/test/th-76-_jpeg_jpg.rf.16ef9f7dbd8c02ae5605b4f9748a73ea.jpg: 640x640 2 ObjectDetecteds, 13.5ms\n","image 87/88 /content/drive/MyDrive/yolov8/test/th-82-_jpeg_jpg.rf.fcde8b24d45a90781ab1e1fb1f5b7ee7.jpg: 640x640 1 ObjectDetected, 13.5ms\n","image 88/88 /content/drive/MyDrive/yolov8/test/th-9-_jpeg_jpg.rf.3ec4e9805006a752dee4b77d31081626.jpg: 640x640 1 ObjectDetected, 13.5ms\n","Speed: 1.8ms preprocess, 14.7ms inference, 8.1ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/predict\n"]}],"source":["!yolo task=detect mode=predict model=/content/drive/MyDrive/yolov8/training_results/plastic_bottle99/weights/best.pt conf=0.55 source=/content/drive/MyDrive/yolov8/test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o1KGlcMKfm_t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708668663016,"user_tz":-330,"elapsed":2968,"user":{"displayName":"Ayyub Hameem","userId":"04962790387129176212"}},"outputId":"4bb8692c-ac06-4824-d182-ef1a3928e737"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cacPbzchx9Ud"},"outputs":[],"source":["!cp -r /content/runs/detect/predict /content/drive/MyDrive/yolov8/output"]},{"cell_type":"code","source":["!cp -r /content/runs/detect/predict3 /content/drive/MyDrive/yolov8/output"],"metadata":{"id":"WugCqZZMhnDa"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jlmZfB0MzOWH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710604910928,"user_tz":-330,"elapsed":10261,"user":{"displayName":"Ayyub Hameem","userId":"04962790387129176212"}},"outputId":"86766771-b79d-48f5-e9fe-437a859473d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'\n","  warnings.warn(\n","Ultralytics YOLOv8.1.29 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n","\n","video 1/1 (frame 1/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 190.3ms\n","video 1/1 (frame 2/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 11.3ms\n","video 1/1 (frame 3/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 11.8ms\n","video 1/1 (frame 4/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 10.7ms\n","video 1/1 (frame 5/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 11.8ms\n","video 1/1 (frame 6/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 10.7ms\n","video 1/1 (frame 7/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 10.9ms\n","video 1/1 (frame 8/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 10.7ms\n","video 1/1 (frame 9/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 10.9ms\n","video 1/1 (frame 10/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 11.7ms\n","video 1/1 (frame 11/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 18.0ms\n","video 1/1 (frame 12/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 17.2ms\n","video 1/1 (frame 13/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 12.7ms\n","video 1/1 (frame 14/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 12.7ms\n","video 1/1 (frame 15/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 12.8ms\n","video 1/1 (frame 16/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 12.9ms\n","video 1/1 (frame 17/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 12.8ms\n","video 1/1 (frame 18/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 12.8ms\n","video 1/1 (frame 19/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 11.9ms\n","video 1/1 (frame 20/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 12.7ms\n","video 1/1 (frame 21/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 13.1ms\n","video 1/1 (frame 22/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 15.7ms\n","video 1/1 (frame 23/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 13.1ms\n","video 1/1 (frame 24/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 10.7ms\n","video 1/1 (frame 25/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 10.7ms\n","video 1/1 (frame 26/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 2 ObjectDetecteds, 10.7ms\n","video 1/1 (frame 27/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 2 ObjectDetecteds, 10.7ms\n","video 1/1 (frame 28/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 2 ObjectDetecteds, 10.7ms\n","video 1/1 (frame 29/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 10.7ms\n","video 1/1 (frame 30/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 10.4ms\n","video 1/1 (frame 31/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 9.8ms\n","video 1/1 (frame 32/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 9.8ms\n","video 1/1 (frame 33/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 9.8ms\n","video 1/1 (frame 34/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 9.8ms\n","video 1/1 (frame 35/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 11.0ms\n","video 1/1 (frame 36/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 9.8ms\n","video 1/1 (frame 37/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 9.8ms\n","video 1/1 (frame 38/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 (no detections), 9.8ms\n","video 1/1 (frame 39/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 (no detections), 9.8ms\n","video 1/1 (frame 40/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 (no detections), 8.5ms\n","video 1/1 (frame 41/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 8.5ms\n","video 1/1 (frame 42/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 2 ObjectDetecteds, 8.5ms\n","video 1/1 (frame 43/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 2 ObjectDetecteds, 8.5ms\n","video 1/1 (frame 44/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 3 ObjectDetecteds, 8.5ms\n","video 1/1 (frame 45/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 3 ObjectDetecteds, 8.5ms\n","video 1/1 (frame 46/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 3 ObjectDetecteds, 8.5ms\n","video 1/1 (frame 47/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 3 ObjectDetecteds, 8.5ms\n","video 1/1 (frame 48/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 8.5ms\n","video 1/1 (frame 49/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 8.5ms\n","video 1/1 (frame 50/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 10.5ms\n","video 1/1 (frame 51/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.9ms\n","video 1/1 (frame 52/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.9ms\n","video 1/1 (frame 53/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.9ms\n","video 1/1 (frame 54/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.9ms\n","video 1/1 (frame 55/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 12.1ms\n","video 1/1 (frame 56/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 9.2ms\n","video 1/1 (frame 57/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.9ms\n","video 1/1 (frame 58/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 8.9ms\n","video 1/1 (frame 59/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.9ms\n","video 1/1 (frame 60/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 10.6ms\n","video 1/1 (frame 61/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.8ms\n","video 1/1 (frame 62/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.8ms\n","video 1/1 (frame 63/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.8ms\n","video 1/1 (frame 64/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.8ms\n","video 1/1 (frame 65/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.8ms\n","video 1/1 (frame 66/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.9ms\n","video 1/1 (frame 67/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.8ms\n","video 1/1 (frame 68/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.8ms\n","video 1/1 (frame 69/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.8ms\n","video 1/1 (frame 70/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.9ms\n","video 1/1 (frame 71/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.4ms\n","video 1/1 (frame 72/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.4ms\n","video 1/1 (frame 73/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.3ms\n","video 1/1 (frame 74/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.4ms\n","video 1/1 (frame 75/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.4ms\n","video 1/1 (frame 76/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 9.1ms\n","video 1/1 (frame 77/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.4ms\n","video 1/1 (frame 78/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.4ms\n","video 1/1 (frame 79/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.4ms\n","video 1/1 (frame 80/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.4ms\n","video 1/1 (frame 81/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.3ms\n","video 1/1 (frame 82/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.1ms\n","video 1/1 (frame 83/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.1ms\n","video 1/1 (frame 84/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.2ms\n","video 1/1 (frame 85/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 8.2ms\n","video 1/1 (frame 86/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.1ms\n","video 1/1 (frame 87/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.1ms\n","video 1/1 (frame 88/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 8.0ms\n","video 1/1 (frame 89/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.2ms\n","video 1/1 (frame 90/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.2ms\n","video 1/1 (frame 91/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.1ms\n","video 1/1 (frame 92/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.2ms\n","video 1/1 (frame 93/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.4ms\n","video 1/1 (frame 94/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.2ms\n","video 1/1 (frame 95/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.2ms\n","video 1/1 (frame 96/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.3ms\n","video 1/1 (frame 97/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.2ms\n","video 1/1 (frame 98/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.5ms\n","video 1/1 (frame 99/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 7.2ms\n","video 1/1 (frame 100/100) /content/drive/MyDrive/yolov8/2.mp4: 640x384 1 ObjectDetected, 8.2ms\n","Speed: 2.5ms preprocess, 11.2ms inference, 9.7ms postprocess per image at shape (1, 3, 640, 384)\n","Results saved to \u001b[1mruns/detect/predict3\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/predict\n"]}],"source":["!yolo task=detect mode=predict model=/content/drive/MyDrive/yolov8/training_results/plastic_bottle99/weights/best.pt conf=0.55 source='/content/drive/MyDrive/yolov8/2.mp4'"]},{"cell_type":"code","source":[],"metadata":{"id":"LyKXT8N2_1cy"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"17yg1yW-3yYwvhQmGRy_ebRJv_mnbl5df","timestamp":1708933634177}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1b3d2f68557f470c9153c522c1330a5a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e2208239901442afbefd4555f9197d3a","IPY_MODEL_42297cceecfd4a7f93bf86a266881cf3","IPY_MODEL_254f26c5acd74a448bec4bf2e88b7480"],"layout":"IPY_MODEL_4d0b86c4a345402e8e31ad436c5c5848"}},"e2208239901442afbefd4555f9197d3a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9dbfd7e5e7442c38b15d3cd29771983","placeholder":"​","style":"IPY_MODEL_c473f02c391f40ec9f1938f4ab7882d0","value":"100%"}},"42297cceecfd4a7f93bf86a266881cf3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f73a3fe95394fdbb33c294017b7d3f1","max":2692,"min":0,"orientation":"horizontal","style":"IPY_MODEL_54ddadeb183d4cf58c4c5f06730e3b92","value":2692}},"254f26c5acd74a448bec4bf2e88b7480":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb867800ccc14169951f917404811556","placeholder":"​","style":"IPY_MODEL_61212a1500b84e77b488c84e70f1c2f4","value":" 2692/2692 [03:34&lt;00:00, 131.51it/s]"}},"4d0b86c4a345402e8e31ad436c5c5848":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9dbfd7e5e7442c38b15d3cd29771983":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c473f02c391f40ec9f1938f4ab7882d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f73a3fe95394fdbb33c294017b7d3f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54ddadeb183d4cf58c4c5f06730e3b92":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fb867800ccc14169951f917404811556":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61212a1500b84e77b488c84e70f1c2f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1496befb56dd4e5cbfa83d14c8fcee10":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_48b32659bb3048a58b347a40461a526f","IPY_MODEL_7c159ef033814aba9050c5270d5bb87d","IPY_MODEL_ff89dfc0cf56442d906334696a021e40"],"layout":"IPY_MODEL_46173f6c83404b45b59cb030a73f3e86"}},"48b32659bb3048a58b347a40461a526f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_490363470fe3465a9bce32e8062f6717","placeholder":"​","style":"IPY_MODEL_20f99fdbf13049d29cf19a5372556d4d","value":"100%"}},"7c159ef033814aba9050c5270d5bb87d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4ce290d6b034d86b608c1b95bd6955a","max":184,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ed5d747828d14741a0b617b30c7d9f0a","value":184}},"ff89dfc0cf56442d906334696a021e40":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8de95aca130e49ef81b9e13daf80f6ad","placeholder":"​","style":"IPY_MODEL_5eb00e1f16874b7c9d8bc45817626c0c","value":" 184/184 [00:13&lt;00:00, 45.15it/s]"}},"46173f6c83404b45b59cb030a73f3e86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"490363470fe3465a9bce32e8062f6717":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20f99fdbf13049d29cf19a5372556d4d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4ce290d6b034d86b608c1b95bd6955a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed5d747828d14741a0b617b30c7d9f0a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8de95aca130e49ef81b9e13daf80f6ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5eb00e1f16874b7c9d8bc45817626c0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89c70fe7139a4f68a732ef5900cb8def":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f1a880563e9048ed897d49a4e608fce5","IPY_MODEL_b586f0966559496e8d85d590a7b3d9ad","IPY_MODEL_a428bb7261ce4c4894345a0491de00fd"],"layout":"IPY_MODEL_454d4ea61f3b468db6becd5b56321ee8"}},"f1a880563e9048ed897d49a4e608fce5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_394d57132d9b4996b9acb52aa0961c08","placeholder":"​","style":"IPY_MODEL_83b8d7063ff440b1bcf766ebd132f70d","value":"100%"}},"b586f0966559496e8d85d590a7b3d9ad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f4ef4e533354b7fab1fd19524a8a338","max":88,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a654b1f7bde24bd99d0c1d31b1f64cb3","value":88}},"a428bb7261ce4c4894345a0491de00fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1652bc354f0d403abfc0fd44649f44f2","placeholder":"​","style":"IPY_MODEL_83e8245dd52c48dfbb6e4e5fffd4e3a0","value":" 88/88 [00:30&lt;00:00,  2.88it/s]"}},"454d4ea61f3b468db6becd5b56321ee8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"394d57132d9b4996b9acb52aa0961c08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83b8d7063ff440b1bcf766ebd132f70d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f4ef4e533354b7fab1fd19524a8a338":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a654b1f7bde24bd99d0c1d31b1f64cb3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1652bc354f0d403abfc0fd44649f44f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83e8245dd52c48dfbb6e4e5fffd4e3a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}